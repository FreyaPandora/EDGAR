{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "\n",
    "def write_page(url, file_path):\n",
    "    \"\"\"Takes in the URL and writes the html file to the path specified.\"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    \n",
    "    try:\n",
    "        xpath_convert_to_html = r'//*[@id=\"form-information-html\"]'\n",
    "        xpath_button_click =r'//*[@id=\"menu-dropdown-link\"]'\n",
    "        \n",
    "        driver.find_element(\"xpath\", xpath_button_click).click()\n",
    "        correct_url =  driver.find_element(\"xpath\", xpath_convert_to_html).get_attribute('href')\n",
    "        \n",
    "        driver.quit()\n",
    "        driver = webdriver.Chrome()\n",
    "        driver.get(correct_url)\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(driver.page_source)\n",
    "        driver.quit()\n",
    "    except:\n",
    "        with open(file_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(driver.page_source)\n",
    "        driver.quit()\n",
    "\n",
    "def download_files_10k(ticker, dest_folder):\n",
    "    \"\"\"Downloads all the html 10-k files for the given ticker into the destination folder.\"\"\"\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "\n",
    "    # Construct the URL to search for the ticker's filings\n",
    "    url = r'https://www.sec.gov/edgar/searchedgar/companysearch'\n",
    "\n",
    "    # Open the search page and enter the ticker in the search box\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    xpath_search_box = r'//*[@id=\"edgar-company-person\"]'\n",
    "    driver.find_element(\"xpath\", xpath_search_box).send_keys(ticker,Keys.ENTER)\n",
    "\n",
    "    # Wait for page to load and expand 10-K dropdown\n",
    "    time.sleep(2)\n",
    "    xpath_expand_selected = r'//*[@id=\"filingsStart\"]/div[2]/div[3]/h5/a'\n",
    "    driver.find_element(\"xpath\", xpath_expand_selected).click()\n",
    "\n",
    "    # views only 10-K and 10-Q data\n",
    "    time.sleep(1)\n",
    "    xpath_obtain_all_data = r'//*[@id=\"filingsStart\"]/div[2]/div[3]/div/button[1]'\n",
    "    driver.find_element(\"xpath\", xpath_obtain_all_data).click()\n",
    "\n",
    "    # Searches 10-K to only show the relevant filings\n",
    "    xpath_search_10K = r'//*[@id=\"searchbox\"]'\n",
    "    driver.find_element(\"xpath\", xpath_search_10K).send_keys('10-K',Keys.ENTER)\n",
    "\n",
    "    # Download each 10-K filing\n",
    "    \n",
    "    # Download each 10-K filing\n",
    "    table_xpath = r'//*[@id=\"filingsTable\"]'\n",
    "    wait = WebDriverWait(driver, 1)\n",
    "    wait.until(EC.presence_of_element_located((By.XPATH, table_xpath)))\n",
    "    table = driver.find_element(By.XPATH, table_xpath)\n",
    "    rows = table.find_elements(By.XPATH, './tbody/tr')\n",
    "\n",
    "    counter = 1\n",
    "    for row in rows:\n",
    "        cells = row.find_elements(By.XPATH, './td')\n",
    "        filing_text = cells[2].text      \n",
    "        xpath_url = '//*[@id=\"filingsTable\"]/tbody/tr['+str(counter)+']/td[2]/div/a[1]'\n",
    "        filing_url = driver.find_element(\"xpath\", xpath_url).get_attribute('href')\n",
    "        file_name = f\"{ticker}_10-K_{filing_text}.html\"\n",
    "        file_path = os.path.join(dest_folder, file_name)\n",
    "        counter += 1\n",
    "        write_page(filing_url, file_path)\n",
    "        \n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean_html_text(html_text):\n",
    "    '''\n",
    "    Function uses BeautifulSoup to parse html text and replaces any tags\n",
    "    or punctuation with a space. '\\W' refers to matching any non-word \n",
    "    defined by regex and '+' refers to matching more than one non-words\n",
    "    '''\n",
    "    soup = BeautifulSoup(html_text, 'html.parser')\n",
    "    stopword_list = stopwords.words('english')\n",
    "    paragraphs = soup.find_all('p')\n",
    "    return_list = []\n",
    "    \n",
    "    for p in paragraphs:\n",
    "        \n",
    "        if not p.find_previous('h1'):\n",
    "            \n",
    "            text = p.get_text(strip=True)\n",
    "            cleaned = re.sub(r'[^A-Za-z0-9]', ' ', text.lower())\n",
    "            clean_text_tokenized = word_tokenize(cleaned)\n",
    "            \n",
    "            for i in stopword_list:\n",
    "                if i in clean_text_tokenized:\n",
    "                    clean_text_tokenized.remove(i)\n",
    "                    \n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            clean_text_lemmatized = [lemmatizer.lemmatize(j) for j in clean_text_tokenized]\n",
    "            regex = re.compile(r'\\d+')\n",
    "            \n",
    "            no_numbers = [item for item in clean_text_lemmatized if not regex.search(item)]\n",
    "            no_letters = [word for word in no_numbers if len(word) != 1]\n",
    "            \n",
    "            if len(no_letters) > 8:\n",
    "                return_list.append(no_letters)\n",
    "    \n",
    "    result = '\\n'.join([' '.join(inner_list) for inner_list in return_list])\n",
    "    \n",
    "    return result   \n",
    "\n",
    "def write_clean_html_text_files(input_folder, dest_folder):\n",
    "    '''\n",
    "    Function reads the files in the input folder and and calls the clean_html_text function\n",
    "    and stores a text file in the destination directory.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "    \n",
    "    for filename in os.listdir(input_folder):\n",
    "        input_file_path = os.path.join(input_folder, filename)\n",
    "        new_name = filename.split('.')\n",
    "        \n",
    "        with open(input_file_path,'r' ,encoding=\"utf8\") as f:\n",
    "            html_text = f.read()\n",
    "            cleaned_text = clean_html_text(html_text)\n",
    "            \n",
    "        dest_filename = f'{new_name[0]}.txt' \n",
    "        dest_file_path = os.path.join(dest_folder, dest_filename)\n",
    "    \n",
    "        \n",
    "        with open(dest_file_path, 'w') as f:\n",
    "            f.write(cleaned_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = r'D:\\Users\\Arian\\Documents\\Kubrick\\Week 10\\EDGAR Project\\data\\10k_filings_raw'\n",
    "ticker = 'AAPL'\n",
    "download_files_10k(ticker, folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = r'D:\\Users\\Arian\\Documents\\Kubrick\\Week 10\\EDGAR Project\\data\\10k_filings_raw'\n",
    "output_folder = r'D:\\Users\\Arian\\Documents\\Kubrick\\Week 10\\EDGAR Project\\data\\10k_filings_clean'\n",
    "write_clean_html_text_files(input_folder, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m user_agent \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     10\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(html_text, headers\u001b[39m=\u001b[39m{\u001b[39m'\u001b[39m\u001b[39mUser-Agent\u001b[39m\u001b[39m'\u001b[39m:user_agent})\n\u001b[1;32m---> 12\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(response\u001b[39m.\u001b[39;49mcontent, \u001b[39m'\u001b[39;49m\u001b[39mhtml.parser\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     13\u001b[0m \u001b[39m# for tag in soup.find_all():\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m#     print(tag.name)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \n\u001b[0;32m     46\u001b[0m \u001b[39m# Finds what the html contains:\u001b[39;00m\n\u001b[0;32m     47\u001b[0m divs \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "input_folder = r'D:\\Users\\Arian\\Documents\\Kubrick\\Week 10\\EDGAR Project\\data\\10k_filings_raw\\AAPL_10-K_2012-10-31.html'\n",
    "import requests\n",
    "import bs4 as BeautifulSoup\n",
    "# with open(input_folder,'r' ,encoding=\"utf8\") as f:\n",
    "#     html_text = f.read()\n",
    "\n",
    "html_text = r'https://www.sec.gov/Archives/edgar/data/320193/000162828016020309/a201610-k9242016.htm'\n",
    "user_agent = r'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36'\n",
    "\n",
    "response = requests.get(html_text, headers={'User-Agent':user_agent})\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "for tag in soup.find_all():\n",
    "    print(tag.name)\n",
    "\n",
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "paragraphs = soup.find_all('p')\n",
    "return_list = []\n",
    "for p in paragraphs:\n",
    "    if not p.find_previous('h1'):\n",
    "        text = p.get_text(strip=True)\n",
    "        clean_text = re.sub(r'[^A-Za-z0-9]', ' ', text.lower())\n",
    "        clean_text_tokenized = word_tokenize(clean_text)\n",
    "        for i in stopword_list:\n",
    "            if i in clean_text_tokenized:\n",
    "                clean_text_tokenized.remove(i)\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        clean_text_lemmatized = [lemmatizer.lemmatize(j) for j in clean_text_tokenized]\n",
    "        \n",
    "        regex = re.compile(r'\\d+')\n",
    "        \n",
    "        no_numbers = [item for item in clean_text_lemmatized if not regex.search(item)]\n",
    "        \n",
    "        no_letters = [word for word in no_numbers if len(word) != 1]\n",
    "        if len(no_letters) > 8:\n",
    "            return_list.append(no_letters)\n",
    "        \n",
    "result = '\\n'.join([' '.join(inner_list) for inner_list in return_list])\n",
    "print(result)\n",
    "        \n",
    "        # if len(text.strip()) != 0:\n",
    "        #     print(p.text.lower())\n",
    "\n",
    "\n",
    "# Finds what the html contains:\n",
    "divs = soup.find_all('div')\n",
    "for div in divs:\n",
    "    spans = div.find_all('span')\n",
    "    for span in spans:\n",
    "        print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3A:\n",
    "import csv\n",
    "import pandas as pd\n",
    "import yahoofinancials\n",
    "from yahoofinancials import YahooFinancials\n",
    "\n",
    "\n",
    "\n",
    "csv_file = 'sp-100-index-03-07-2023.csv'\n",
    "def get_sp100():\n",
    "    # sp100 = []\n",
    "    # with open(csv_file,newline='\\n'):\n",
    "    #     csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    #     for row in csv_reader:\n",
    "    #         sp100.append(row)\n",
    "    #     return df, sp100\n",
    "    df =pd.read_csv(csv_file)\n",
    "    \n",
    "    return list(df['Symbol'])\n",
    "\n",
    "\n",
    "\n",
    "def get_yahoo_data(start_date,end_date,tickers):\n",
    "\n",
    "\n",
    "    for ticker in tickers:\n",
    "        data = YahooFinancials(ticker).get_historical_price_data(start_date, end_date, 'daily')\n",
    "        prices = pd.DataFrame(data[ticker]['prices'])\n",
    "        prices['1daily_return'] = prices['open'] - prices['close'].shift(1)\n",
    "        return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>adjclose</th>\n",
       "      <th>formatted_date</th>\n",
       "      <th>1daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>946909800</td>\n",
       "      <td>25.53125</td>\n",
       "      <td>23.87500</td>\n",
       "      <td>25.1250</td>\n",
       "      <td>25.18750</td>\n",
       "      <td>2493200</td>\n",
       "      <td>14.863492</td>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>946996200</td>\n",
       "      <td>24.87500</td>\n",
       "      <td>24.09375</td>\n",
       "      <td>24.6875</td>\n",
       "      <td>24.46875</td>\n",
       "      <td>1527000</td>\n",
       "      <td>14.439350</td>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>-0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>947082600</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>24.12500</td>\n",
       "      <td>24.5625</td>\n",
       "      <td>24.93750</td>\n",
       "      <td>1755400</td>\n",
       "      <td>14.715969</td>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>0.09375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>947169000</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>24.15625</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>24.71875</td>\n",
       "      <td>1663200</td>\n",
       "      <td>14.586878</td>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>0.06250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>947255400</td>\n",
       "      <td>25.50000</td>\n",
       "      <td>24.53125</td>\n",
       "      <td>24.6250</td>\n",
       "      <td>25.40625</td>\n",
       "      <td>2078400</td>\n",
       "      <td>14.992577</td>\n",
       "      <td>2000-01-07</td>\n",
       "      <td>-0.09375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5173</th>\n",
       "      <td>1595856600</td>\n",
       "      <td>6.44000</td>\n",
       "      <td>6.12000</td>\n",
       "      <td>6.4400</td>\n",
       "      <td>6.21000</td>\n",
       "      <td>26162900</td>\n",
       "      <td>5.942723</td>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>-0.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5174</th>\n",
       "      <td>1595943000</td>\n",
       "      <td>6.55000</td>\n",
       "      <td>6.15000</td>\n",
       "      <td>6.2000</td>\n",
       "      <td>6.43000</td>\n",
       "      <td>23990700</td>\n",
       "      <td>6.153255</td>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>-0.01000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5175</th>\n",
       "      <td>1596029400</td>\n",
       "      <td>6.72000</td>\n",
       "      <td>6.42000</td>\n",
       "      <td>6.4600</td>\n",
       "      <td>6.49000</td>\n",
       "      <td>22529400</td>\n",
       "      <td>6.210672</td>\n",
       "      <td>2020-07-29</td>\n",
       "      <td>0.03000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5176</th>\n",
       "      <td>1596115800</td>\n",
       "      <td>6.45000</td>\n",
       "      <td>6.18000</td>\n",
       "      <td>6.3500</td>\n",
       "      <td>6.22000</td>\n",
       "      <td>18802400</td>\n",
       "      <td>5.952293</td>\n",
       "      <td>2020-07-30</td>\n",
       "      <td>-0.14000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5177</th>\n",
       "      <td>1596202200</td>\n",
       "      <td>6.32000</td>\n",
       "      <td>6.00000</td>\n",
       "      <td>6.2600</td>\n",
       "      <td>6.06000</td>\n",
       "      <td>23020600</td>\n",
       "      <td>5.799179</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>0.04000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5178 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date      high       low     open     close    volume   adjclose  \\\n",
       "0      946909800  25.53125  23.87500  25.1250  25.18750   2493200  14.863492   \n",
       "1      946996200  24.87500  24.09375  24.6875  24.46875   1527000  14.439350   \n",
       "2      947082600  25.00000  24.12500  24.5625  24.93750   1755400  14.715969   \n",
       "3      947169000  25.00000  24.15625  25.0000  24.71875   1663200  14.586878   \n",
       "4      947255400  25.50000  24.53125  24.6250  25.40625   2078400  14.992577   \n",
       "...          ...       ...       ...      ...       ...       ...        ...   \n",
       "5173  1595856600   6.44000   6.12000   6.4400   6.21000  26162900   5.942723   \n",
       "5174  1595943000   6.55000   6.15000   6.2000   6.43000  23990700   6.153255   \n",
       "5175  1596029400   6.72000   6.42000   6.4600   6.49000  22529400   6.210672   \n",
       "5176  1596115800   6.45000   6.18000   6.3500   6.22000  18802400   5.952293   \n",
       "5177  1596202200   6.32000   6.00000   6.2600   6.06000  23020600   5.799179   \n",
       "\n",
       "     formatted_date  1daily_return  \n",
       "0        2000-01-03            NaN  \n",
       "1        2000-01-04       -0.50000  \n",
       "2        2000-01-05        0.09375  \n",
       "3        2000-01-06        0.06250  \n",
       "4        2000-01-07       -0.09375  \n",
       "...             ...            ...  \n",
       "5173     2020-07-27       -0.01000  \n",
       "5174     2020-07-28       -0.01000  \n",
       "5175     2020-07-29        0.03000  \n",
       "5176     2020-07-30       -0.14000  \n",
       "5177     2020-07-31        0.04000  \n",
       "\n",
       "[5178 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df_returns = get_yahoo_data('2000-01-01', '2020-08-01', 'MMM')\n",
    "display(df_returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
